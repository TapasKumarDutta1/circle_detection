{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0WnymAZtkgo",
        "outputId": "2f95e62e-9abd-48f6-b401-5718b49597c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'circle_detection'...\n",
            "remote: Enumerating objects: 30, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 30 (delta 6), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (30/30), 9.85 KiB | 4.92 MiB/s, done.\n",
            "Resolving deltas: 100% (6/6), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/TapasKumarDutta1/circle_detection.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/circle_detection')"
      ],
      "metadata": {
        "id": "alDEWTc0ttW_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from generate_dataset import generate\n",
        "from torchvision import models\n",
        "from torch import nn\n",
        "import glob\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from dataset import CustomDataset\n",
        "from torch import optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch\n",
        "from evaluation import check_iou\n",
        "generate(10000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OSFBBMPtr__",
        "outputId": "67d4002b-f719-40bb-d01c-dc9ed5eff9f5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "80it [00:00, 773.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using parameters: noise_level=0.5, img_size=100, min_radius=10, max_radius=50, dataset_path='ds'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "12999it [00:16, 765.57it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "path_of_the_directory = \"/content/train/labels\"\n",
        "ext = \".txt\"\n",
        "files_train = []\n",
        "loc_x_train = []\n",
        "loc_y_train = []\n",
        "radiuses_train = []\n",
        "for file in os.listdir(path_of_the_directory):\n",
        "    if file.endswith(ext):\n",
        "        f = open(os.path.join(path_of_the_directory, file), \"r\")\n",
        "        files_train.append(\n",
        "            os.path.join(path_of_the_directory, file)\n",
        "            .replace(\"labels\", \"images\")\n",
        "            .replace(\".txt\", \"\")\n",
        "        )\n",
        "        loc_x_train.append(int(f.readline()))\n",
        "        loc_y_train.append(int(f.readline().replace(\"\\n\", \"\")))\n",
        "        radiuses_train.append(int(f.readline().replace(\"\\n\", \"\")))\n"
      ],
      "metadata": {
        "id": "8HT6WGNrtr9X"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_of_the_directory = \"/content/valid/labels\"\n",
        "ext = \".txt\"\n",
        "files_valid = []\n",
        "loc_x_valid = []\n",
        "loc_y_valid = []\n",
        "radiuses_valid = []\n",
        "for file in os.listdir(path_of_the_directory):\n",
        "    if file.endswith(ext):\n",
        "        f = open(os.path.join(path_of_the_directory, file), \"r\")\n",
        "        files_valid.append(\n",
        "            os.path.join(path_of_the_directory, file)\n",
        "            .replace(\"labels\", \"images\")\n",
        "            .replace(\".txt\", \"\")\n",
        "        )\n",
        "        loc_x_valid.append(int(f.readline()))\n",
        "        loc_y_valid.append(int(f.readline().replace(\"\\n\", \"\")))\n",
        "        radiuses_valid.append(int(f.readline().replace(\"\\n\", \"\")))\n"
      ],
      "metadata": {
        "id": "SIYnhBgqtr6i"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_of_the_directory = \"/content/test/labels\"\n",
        "ext = \".txt\"\n",
        "files_test = []\n",
        "loc_x_test = []\n",
        "loc_y_test = []\n",
        "radiuses_test = []\n",
        "for file in os.listdir(path_of_the_directory):\n",
        "    if file.endswith(ext):\n",
        "        f = open(os.path.join(path_of_the_directory, file), \"r\")\n",
        "        files_test.append(\n",
        "            os.path.join(path_of_the_directory, file)\n",
        "            .replace(\"labels\", \"images\")\n",
        "            .replace(\".txt\", \"\")\n",
        "        )\n",
        "        loc_x_test.append(int(f.readline()))\n",
        "        loc_y_test.append(int(f.readline().replace(\"\\n\", \"\")))\n",
        "        radiuses_test.append(int(f.readline().replace(\"\\n\", \"\")))\n"
      ],
      "metadata": {
        "id": "i5UIAswVtr3Y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls = []\n",
        "for i in glob.glob(\"/content/train/images/*.npy\"):\n",
        "    ls.append(np.load(i, allow_pickle=True))\n",
        "mean, std = np.mean(np.stack(ls)), np.std(np.stack(ls))\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((mean, mean, mean), (std, std, std))]\n",
        ")\n",
        "\n",
        "test_transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((mean, mean, mean), (std, std, std))]\n",
        ")\n",
        "\n",
        "batch_size = 10\n",
        "\n",
        "dataset_stages = [\"train\", \"val\", \"test\"]\n",
        "image_datasets = {\n",
        "    \"train\": CustomDataset(\n",
        "        files_train, loc_x_train, loc_y_train, radiuses_train, batch_size, transform\n",
        "    ),\n",
        "    \"val\": CustomDataset(\n",
        "        files_valid,\n",
        "        loc_x_valid,\n",
        "        loc_y_valid,\n",
        "        radiuses_valid,\n",
        "        batch_size,\n",
        "        test_transform,\n",
        "    ),\n",
        "    \"test\": CustomDataset(\n",
        "        files_test, loc_x_test, loc_y_test, radiuses_test, batch_size, test_transform\n",
        "    ),\n",
        "}\n",
        "\n",
        "dataloaders = {\n",
        "    x: DataLoader(\n",
        "        image_datasets[x],\n",
        "        batch_size=image_datasets[x].BatchSize,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "    )\n",
        "    for x in dataset_stages\n",
        "}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"val\"]}\n",
        "model = models.shufflenet_v2_x1_0()\n",
        "model.fc = nn.Linear(in_features=1024, out_features=3, bias=True)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, \"min\")\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "OcOk-0VVtr0h"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from training import train_model\n",
        "model, _ = train_model(\n",
        "    model,\n",
        "    dataloaders[\"train\"],\n",
        "    dataloaders[\"val\"],\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    device,\n",
        "    50,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQcA0Bmgtrx7",
        "outputId": "6c043737-f226-4cbf-8ace-7972c9592b6a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:48<00:00, 20.47it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 41.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], train_loss: 0.0541, val_loss: 0.0040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:51<00:00, 19.27it/s]\n",
            "100%|██████████| 100/100 [00:01<00:00, 55.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1], train_loss: 0.0053, val_loss: 0.0033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:39<00:00, 25.37it/s]\n",
            "100%|██████████| 100/100 [00:01<00:00, 54.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2], train_loss: 0.0038, val_loss: 0.0024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:39<00:00, 25.53it/s]\n",
            "100%|██████████| 100/100 [00:01<00:00, 53.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3], train_loss: 0.0027, val_loss: 0.0021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:39<00:00, 25.40it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 49.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4], train_loss: 0.0029, val_loss: 0.0016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:39<00:00, 25.55it/s]\n",
            "100%|██████████| 100/100 [00:01<00:00, 53.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5], train_loss: 0.0021, val_loss: 0.0090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:39<00:00, 25.53it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 49.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6], train_loss: 0.0017, val_loss: 0.0016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:39<00:00, 25.55it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 40.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7], train_loss: 0.0009, val_loss: 0.0011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:39<00:00, 25.47it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 41.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8], train_loss: 0.0008, val_loss: 0.0015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:38<00:00, 25.69it/s]\n",
            "100%|██████████| 100/100 [00:01<00:00, 51.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9], train_loss: 0.0035, val_loss: 0.0025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:39<00:00, 25.41it/s]\n",
            "100%|██████████| 100/100 [00:01<00:00, 53.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10], train_loss: 0.0013, val_loss: 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:39<00:00, 25.41it/s]\n",
            "100%|██████████| 100/100 [00:01<00:00, 55.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11], train_loss: 0.0007, val_loss: 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:38<00:00, 25.65it/s]\n",
            "100%|██████████| 100/100 [00:01<00:00, 54.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12], train_loss: 0.0005, val_loss: 0.0008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:38<00:00, 25.71it/s]\n",
            "100%|██████████| 100/100 [00:01<00:00, 55.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13], train_loss: 0.0005, val_loss: 0.0009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:39<00:00, 25.50it/s]\n",
            "100%|██████████| 100/100 [00:01<00:00, 54.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14], train_loss: 0.0017, val_loss: 0.0014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:39<00:00, 25.58it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 49.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15], train_loss: 0.0007, val_loss: 0.0007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:39<00:00, 25.63it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 48.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16], train_loss: 0.0005, val_loss: 0.0006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:38<00:00, 25.84it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 39.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17], train_loss: 0.0004, val_loss: 0.0007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:39<00:00, 25.37it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 46.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18], train_loss: 0.0005, val_loss: 0.0009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:39<00:00, 25.52it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 49.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19], train_loss: 0.0007, val_loss: 0.0017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:39<00:00, 25.35it/s]\n",
            "100%|██████████| 100/100 [00:01<00:00, 51.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20], train_loss: 0.0016, val_loss: 0.0013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:39<00:00, 25.39it/s]\n",
            "100%|██████████| 100/100 [00:01<00:00, 55.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [21], train_loss: 0.0006, val_loss: 0.0011\n",
            "Early stopping after 22 epochs without improvement.\n",
            "Training complete in 15m 36s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_iou(model, dataloaders['test'], device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8hBv7gmtrpV",
        "outputId": "37385320-9ece-4f32-ecdb-e67a46c10a6b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9895"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls=[]\n",
        "for i in range(50,95,5):\n",
        "  ls.append(check_iou(model, dataloaders['test'], device,i/100))\n",
        "np.mean(ls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBVTM74owwf-",
        "outputId": "29e33147-1290-43f5-91dc-da0495984be7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8203333333333334"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}